# Copyright (C) 2023 Assistance.Chat contributors

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import asyncio
import json
import textwrap

from assistance._config import DEFAULT_OPENAI_MODEL
from assistance._keys import get_openai_api_key
from assistance._logging import log_info
from assistance._openai import get_completion_only

from .indexer import hash_for_docstring

OPEN_AI_API_KEY = get_openai_api_key()

MODEL_KWARGS = {
    "engine": DEFAULT_OPENAI_MODEL,
    "max_tokens": 2048,
    "temperature": 0.7,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
}


DOCSTRING_INSTRUCTIONS = textwrap.dedent(
    """
        It is your job to write the docstring in numpydoc of python
        function docstring that fulfils this task.

        When writing the docstring do not include examples or notes.
        Keep the function as simple as possible, but no simpler.
    """
).strip()


INITIAL_PROMPT = (
    textwrap.dedent(
        """\
        # Writing a docstring for a function that fulfil a task

        ## Instructions

        {DOCSTRING_INSTRUCTIONS}

        ## Your task

        {task}

        ## Example response

        Calls a large language model (LLM) with the given prompt and
        returns the generated response.

        Parameters
        ----------
        prompt : str
            The input prompt to be used when calling the LLM.

        Returns
        -------
        str
            The generated response from the LLM

        ## Your response
"""
    )
    .strip()
    .replace("{DOCSTRING_INSTRUCTIONS}", DOCSTRING_INSTRUCTIONS)
)


PROMPT = (
    textwrap.dedent(
        r"""\
        # Writing a list of docstrings for functions that fulfil a task

        ## Instructions

        You have been provided with a current task and an original task.
        The current task has been derived from the original task. You
        are aiming to complete the current task while keeping in mind
        that it your approach stays relevant to the original task.

        {DOCSTRING_INSTRUCTIONS}

        ## Your current task

        You are aiming to create a function that meets the requirement
        of the following docstring:

        ```
        {docstring}
        ```

        It is your task to create a range of functions that you would
        like to use within the function that you create for the above
        docstring.

        Only include functions that are relevant to the original task
        and are not overly simple where the implementation would be
        one line of code.

        ## The original task

        {task}

        ## Required JSON format

        [
            "<1st docstring>",
            "<2nd docstring>",
            ...
            "<nth docstring>"
        ]

        ## First example response

        [
            "Calls a large language model (LLM) with the given prompt and\nreturns the generated response.\n\nParameters\n----------\nprompt : str\n    The input prompt to be used when calling the LLM.\n\nReturns\n-------\nstr\n    The generated response from the LLM based on the input prompt.",
            "Returns the current date and time in ISO format.\n\nReturns\n-------\nstr\n    The current date and time in ISO 8601 format (YYYY-MM-DDTHH:MM:SS).",
            "Uses a large language model (LLM) to generate a summary of the\ninput text based on the given instruction.\n\nParameters\n----------\ntext : str\n    The input text to be summarized by the LLM.\ninstruction : str\n    The instruction to guide the LLM in generating a focused summary\n    of the input text.\n\nReturns\n-------\nstr\n    The focused summary of the input text generated by the LLM based on\n    the provided instruction."
        ]


        ## Second example response

        []

        ## Third example response

        [
            "Extracts all email addresses from the input text using a regular expression pattern.\n\nParameters\n----------\ntext : str\n    The input text to extract email addresses from.\n\nReturns\n-------\nlist[str]\n    The list of email addresses extracted from the input text."
        ]

        ## Your JSON response (ONLY respond with JSON, nothing else)
    """
    )
    .strip()
    .replace("{DOCSTRING_INSTRUCTIONS}", DOCSTRING_INSTRUCTIONS)
)


async def generate(
    scope: str,
    task: str,
    docstring: str | None = None,
    max_depth=3,
    current_depth=0,
) -> set[str]:
    if current_depth >= max_depth:
        return set()

    if docstring is None:
        log_info(scope, "Generating initial docstring")
        docstring = await get_completion_only(
            scope=scope,
            prompt=INITIAL_PROMPT.format(task=task),
            api_key=OPEN_AI_API_KEY,
            **MODEL_KWARGS,
        )

        assert docstring is not None

    docstring_hash = hash_for_docstring(docstring)

    # Test if this docstring exists, if it does return hash of existing docstring

    log_info(scope, f"Generating child docstrings for {docstring_hash[0:8]}")
    child_docstrings = await _run_with_error_loop(
        scope=scope,
        prompt=PROMPT.format(task=task, docstring=docstring),
        api_key=OPEN_AI_API_KEY,
        model_kwargs=MODEL_KWARGS,
    )

    coroutines = []
    for child_docstring in child_docstrings:
        # TODO: Only create sub-docstrings if this current docstring doesn't
        # already have a function that fulfils it.

        # TODO:
        # - Search here for created functions
        # - Return the found functions
        # - Ask a separate agent, do any of these found functions sufficiently match the desired docstring?
        # - If so, return the found functions
        # - If not, create a new function starting with the following approach

        coroutines.append(
            generate(
                scope,
                task=task,
                docstring=child_docstring,
                max_depth=max_depth,
                current_depth=current_depth + 1,
            )
        )

    sub_docstrings = await asyncio.gather(*coroutines)

    return {docstring}.union(child_docstrings).union(*sub_docstrings)


ERROR_MESSAGE_TEMPLATE = textwrap.dedent(
    """
        # Error Message

        You previously attempted the prompt below, however, when
        attempting to run `json.loads(response)` on the response you
        previously provided the following error was raised:

        {error}

        The response you previously provided was:

        {response}
    """
).strip()


async def _run_with_error_loop(scope, prompt, api_key, model_kwargs, prepend=""):
    error_message = ""

    while True:
        response = await get_completion_only(
            scope=scope,
            prompt=error_message + prompt,
            api_key=api_key,
            **model_kwargs,
        )

        response = prepend + response

        log_info(scope, response)

        try:
            data = json.loads(response)
        except json.JSONDecodeError as e:
            error_message = (
                ERROR_MESSAGE_TEMPLATE.format(error=repr(e), response=response) + "\n\n"
            )
            continue

        return data
