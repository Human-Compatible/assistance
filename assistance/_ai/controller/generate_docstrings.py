# Copyright (C) 2023 Assistance.Chat contributors

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import asyncio
import json
import textwrap

from assistance._config import DEFAULT_OPENAI_MODEL
from assistance._keys import get_openai_api_key
from assistance._logging import log_info
from assistance._openai import get_completion_only

OPEN_AI_API_KEY = get_openai_api_key()

MODEL_KWARGS = {
    "engine": DEFAULT_OPENAI_MODEL,
    "max_tokens": 2048,
    "temperature": 0.7,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
}


PROMPT = textwrap.dedent(
    r"""
        # Writing a list of docstrings for functions that fulfil a task

        ## Instructions

        You have been provided with a current task and an original task.
        The current task has been derived from the original task. You
        are aiming to complete the current task while keeping in mind
        that it your approach stays relevant to the original task.

        It is your job to provide a list of python function docstring in numpydoc
        format that would be useful for fulfilling your task.

        When writing the docstrings do not include examples or notes.
        Keep the function as simple as possible, but no simpler.

        Make sure that your docstring describes what the function does
        not *how* it does it. A function definition shouldn't be
        restricted by implementation details.

        ## Your current task

        {task}

        ## The original task

        {original_task}

        ## Required JSON format

        [
            "<1st docstring>",
            "<2nd docstring>",
            ...
            "<nth docstring>"
        ]

        ## Example response

        [
            "Calls a large language model (LLM) with the given prompt and\nreturns the generated response.\n\nParameters\n----------\nprompt : str\n    The input prompt to be used when calling the LLM.\n\nReturns\n-------\nstr\n    The generated response from the LLM based on the input prompt.",
            "Returns the current date and time in ISO format.\n\nReturns\n-------\nstr\n    The current date and time in ISO 8601 format (YYYY-MM-DDTHH:MM:SS).",
            "Uses a large language model (LLM) to generate a summary of the\ninput text based on the given instruction.\n\nParameters\n----------\ntext : str\n    The input text to be summarized by the LLM.\ninstruction : str\n    The instruction to guide the LLM in generating a focused summary\n    of the input text.\n\nReturns\n-------\nstr\n    The focused summary of the input text generated by the LLM based on\n    the provided instruction.",
            "Extracts all email addresses from the input text using a regular expression pattern.\n\nParameters\n----------\ntext : str\n    The input text to extract email addresses from.\n\nReturns\n-------\nlist[str]\n    The list of email addresses extracted from the input text."
        ]

        ## Your JSON response (ONLY respond with JSON, nothing else)
    """
).strip()


CREATE_FUNCTION_TASK = textwrap.dedent(
    """
        You are aiming to create a function that meets the requirement
        of the following docstring:

        {docstring}

        It is your task to create a range of functions that you would
        like to use within the function that you create for the above
        docstring.
    """
).strip()


async def generate_docstrings(
    scope: str,
    task: str,
    original_task: str | None = None,
    max_depth=3,
    current_depth=0,
) -> set[str]:
    if current_depth >= max_depth:
        return set()

    if original_task is None:
        original_task = task

    docstrings = await _run_with_error_loop(
        scope=scope,
        prompt=PROMPT.format(task=task, original_task=original_task),
        api_key=OPEN_AI_API_KEY,
        model_kwargs=MODEL_KWARGS,
    )

    coroutines = []
    for docstring in docstrings:
        # TODO: Only create sub-docstrings if this current docstring doesn't
        # already have a function that fulfils it.

        # TODO:
        # - Search here for created functions
        # - Return the found functions
        # - Ask a separate agent, do any of these found functions sufficiently match the desired docstring?
        # - If so, return the found functions
        # - If not, create a new function starting with the following approach

        new_task = CREATE_FUNCTION_TASK.format(docstring=docstring)
        coroutines.append(
            generate_docstrings(
                scope,
                task=new_task,
                max_depth=max_depth,
                current_depth=current_depth + 1,
            )
        )

    sub_docstrings = await asyncio.gather(*coroutines)

    return set(docstrings).union(*sub_docstrings)


ERROR_MESSAGE_TEMPLATE = textwrap.dedent(
    """
        # Error Message

        You previously attempted the prompt below, however, when
        attempting to run `json.loads(response)` on the response you
        previously provided the following error was raised:

        {error}

        The response you previously provided was:

        {response}
    """
).strip()


async def _run_with_error_loop(scope, prompt, api_key, model_kwargs):
    error_message = ""

    while True:
        response = await get_completion_only(
            scope=scope,
            prompt=error_message + prompt,
            api_key=api_key,
            **model_kwargs,
        )

        log_info(scope, response)

        try:
            data = json.loads(response)
        except json.JSONDecodeError as e:
            error_message = (
                ERROR_MESSAGE_TEMPLATE.format(error=repr(e), response=response) + "\n\n"
            )
            continue

        return data
