# Copyright (C) 2023 Assistance.Chat contributors

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import asyncio
import json
import textwrap

import aiofiles

from assistance._config import DEFAULT_OPENAI_MODEL
from assistance._embeddings import get_closest_functions
from assistance._keys import get_openai_api_key
from assistance._logging import log_info
from assistance._openai import get_completion_only
from assistance._paths import AI_REGISTRY_DIR

from .indexer import hash_for_docstring

OPEN_AI_API_KEY = get_openai_api_key()

MODEL_KWARGS = {
    "engine": DEFAULT_OPENAI_MODEL,
    "max_tokens": 2048,
    "temperature": 0,
}


DOCSTRING_INSTRUCTIONS = textwrap.dedent(
    """
        When you write a docstring it is to be in the numpydoc format.

        When writing a docstring do not include examples or notes.
        Keep the function referred to by the docstring as simple as
        possible, but no simpler.
    """
).strip()


INITIAL_PROMPT = (
    textwrap.dedent(
        """\
        # Writing a docstring for a function to fulfil a task

        ## Instructions

        {DOCSTRING_INSTRUCTIONS}

        ## Your task

        {task}

        ## Example response

        Calls a large language model (LLM) with the given prompt and
        returns the generated response.

        Parameters
        ----------
        prompt : str
            The input prompt to be used when calling the LLM.

        Returns
        -------
        str
            The generated response from the LLM

        ## Your response
"""
    )
    .strip()
    .replace("{DOCSTRING_INSTRUCTIONS}", DOCSTRING_INSTRUCTIONS)
)


PROMPT = (
    textwrap.dedent(
        r"""\
        # Writing a list of child docstrings for a parent docstring

        ## Instructions

        You are a single component of an AI cluster.

        You are aiming to create a list of child docstrings in order to
        help the cluster of AI agents write a library of functions that
        achieves the original task.

        DO NOT create docstrings for the original task itself, other
        AI agents will be doing that. Instead, only create docstrings
        for functions that will be explicitly helpful in the creation
        of your given parent docstring.

        {DOCSTRING_INSTRUCTIONS}

        ## Your parent docstring

        {docstring}

        ## The original task

        {task}

        ## Required JSON format

        [
            "<1st docstring>",
            "<2nd docstring>",
            ...
            "<nth docstring>"
        ]

        ## First example response

        [
            "Calls a large language model (LLM) with the given prompt and\nreturns the generated response.\n\nParameters\n----------\nprompt : str\n    The input prompt to be used when calling the LLM.\n\nReturns\n-------\nstr\n    The generated response from the LLM based on the input prompt.",
            "Returns the current date and time in ISO format.\n\nReturns\n-------\nstr\n    The current date and time in ISO 8601 format (YYYY-MM-DDTHH:MM:SS).",
            "Uses a large language model (LLM) to generate a summary of the\ninput text based on the given instruction.\n\nParameters\n----------\ntext : str\n    The input text to be summarized by the LLM.\ninstruction : str\n    The instruction to guide the LLM in generating a focused summary\n    of the input text.\n\nReturns\n-------\nstr\n    The focused summary of the input text generated by the LLM based on\n    the provided instruction."
        ]


        ## Second example response

        []

        ## Third example response

        [
            "Extracts all email addresses from the input text using a regular expression pattern.\n\nParameters\n----------\ntext : str\n    The input text to extract email addresses from.\n\nReturns\n-------\nlist[str]\n    The list of email addresses extracted from the input text."
        ]

        ## Your JSON response (ONLY respond with JSON, nothing else)
    """
    )
    .strip()
    .replace("{DOCSTRING_INSTRUCTIONS}", DOCSTRING_INSTRUCTIONS)
)

SIMILAR_PROMPT = textwrap.dedent(
    """\
        # Docstring comparison

        ## Instructions

        You are comparing a base docstring to a series of similar
        docstrings. It is your goal to determine which of the docstrings
        is most similar to the base docstring.

        You are then to determine if the function produced by the most
        similar docstring is the same as the function produced by the
        base docstring.

        ## Base docstring

        {base_docstring}

        ## Similar docstrings

        {similar_docstrings}

        ## Required JSON format

        {{
            "most_similar": <index of most similar docstring>,
            "same_function": <boolean>
        }}

        ## Your JSON response (ONLY respond with JSON, nothing else)
"""
).strip()


async def generate_docstrings(
    scope: str,
    task: str,
    docstring: str | None = None,
    max_depth=3,
    current_depth=0,
    force_dependency_check=False,
) -> str:
    if docstring is None:
        log_info(scope, "Generating initial docstring")
        docstring = await get_completion_only(
            scope=scope,
            prompt=INITIAL_PROMPT.format(task=task),
            api_key=OPEN_AI_API_KEY,
            **MODEL_KWARGS,
        )

        assert docstring is not None

    docstring_hash = hash_for_docstring(docstring)

    if current_depth >= max_depth:
        return docstring_hash

    docstring_registry_path = AI_REGISTRY_DIR.joinpath(
        "docstrings", f"{docstring_hash}.txt"
    )
    dependencies_registry_path = AI_REGISTRY_DIR.joinpath(
        "dependencies", f"{docstring_hash}.json"
    )

    if docstring_registry_path.exists():
        if not force_dependency_check:
            log_info(
                scope,
                f"Skipping docstring generation for {docstring_hash[0:8]} as it has already been generated",
            )
            return docstring_hash

        if dependencies_registry_path.exists():
            return docstring_hash

    similar_docstring_hashes, similar_docstrings = await get_closest_functions(
        openai_api_key=OPEN_AI_API_KEY, docstring=docstring
    )

    if len(similar_docstrings) != 0:
        similar_docstrings_with_indices = [
            f"[{i}]\n{item}" for i, item in enumerate(similar_docstrings)
        ]
        similar_docstrings_text = "\n\n".join(similar_docstrings_with_indices)
        is_it_the_same_data = await _run_with_error_loop(
            scope=scope,
            prompt=SIMILAR_PROMPT.format(
                base_docstring=docstring, similar_docstrings=similar_docstrings_text
            ),
            api_key=OPEN_AI_API_KEY,
            model_kwargs=MODEL_KWARGS,
        )

        if is_it_the_same_data["same_function"]:
            index_of_most_similar = is_it_the_same_data["most_similar"]
            equivalent_hash = similar_docstring_hashes[index_of_most_similar]

            return equivalent_hash

    async with aiofiles.open(docstring_registry_path, "w") as f:
        await f.write(docstring)

    log_info(scope, f"Generating child docstrings for {docstring_hash[0:8]}")
    child_docstrings = await _run_with_error_loop(
        scope=scope,
        prompt=PROMPT.format(task=task, docstring=docstring),
        api_key=OPEN_AI_API_KEY,
        model_kwargs=MODEL_KWARGS,
    )

    coroutines = []
    for child_docstring in child_docstrings:
        coroutines.append(
            generate_docstrings(
                scope,
                task=task,
                docstring=child_docstring,
                max_depth=max_depth,
                current_depth=current_depth + 1,
            )
        )

    child_docstring_hashes = await asyncio.gather(*coroutines)

    async with aiofiles.open(dependencies_registry_path, "w") as f:
        await f.write(json.dumps(child_docstring_hashes, indent=2))

    return docstring_hash


ERROR_MESSAGE_TEMPLATE = textwrap.dedent(
    """
        # Error Message

        You previously attempted the prompt below, however, when
        attempting to run `json.loads(response)` on the response you
        previously provided the following error was raised:

        {error}

        The response you previously provided was:

        {response}
    """
).strip()


async def _run_with_error_loop(scope, prompt, api_key, model_kwargs, prepend=""):
    error_message = ""

    while True:
        response = await get_completion_only(
            scope=scope,
            prompt=error_message + prompt,
            api_key=api_key,
            **model_kwargs,
        )

        response = prepend + response

        log_info(scope, response)

        try:
            data = json.loads(response)
        except json.JSONDecodeError as e:
            error_message = (
                ERROR_MESSAGE_TEMPLATE.format(error=repr(e), response=response) + "\n\n"
            )
            continue

        return data
